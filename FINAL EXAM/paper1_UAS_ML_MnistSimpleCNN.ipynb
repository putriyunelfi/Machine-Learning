{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/putriyunelfi/Machine-Learning/blob/main/FINAL%20EXAM/paper1_UAS_ML_MnistSimpleCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5TM-StAfmZwE"
      },
      "outputs": [],
      "source": [
        "# imports \n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim #optimasi\n",
        "import random #pemilihan acak\n",
        "import torchvision.transforms.functional as A #import transform\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e59GfDyydbgS"
      },
      "outputs": [],
      "source": [
        "#membuat class EMA untuk dipanggil pada saat train\n",
        "class EMA:\n",
        "    def __init__(self, model, decay): #inisialisasi \n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.original = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def __call__(self, model, num_updates): #memanggil update\n",
        "        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def assign(self, model): #menetapkan parameter\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                self.original[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def resume(self, model): #lanjutan\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                param.data = self.original[name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PUvC9cvqvC9r"
      },
      "outputs": [],
      "source": [
        "#Membuat kelas transform untuk dipanggil pada saat train data\n",
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, seed=1):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "        random.seed(seed)\n",
        "    \n",
        "    @staticmethod #memanggil fungsi secara langsung\n",
        "    def get_params(degrees):\n",
        "        angle = random.uniform(degrees[0], degrees[1])\n",
        "        return angle #mengembalikan nilai\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = self.get_params(self.degrees)\n",
        "        return A.rotate(img, angle, False, False, None, None) #mengembalika nilai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9d-3cnCEmBFl"
      },
      "outputs": [],
      "source": [
        "#membuat kelas dataset \n",
        "class MnistDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, training=True, transform=None):\n",
        "        if training==True:\n",
        "          #membuka file data yang tersimpan pada drive\n",
        "            f = open('/content/drive/MyDrive/MnistSimpleCNN-master/data/MNIST/raw/train-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/drive/MyDrive/MnistSimpleCNN-master/data/MNIST/raw/train-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        else:\n",
        "            f = open('/content/drive/MyDrive/MnistSimpleCNN-master/data/MNIST/raw/t10k-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/drive/MyDrive/MnistSimpleCNN-master/data/MNIST/raw/t10k-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        xs = np.reshape(xs, (-1, 28, 28, 1)).astype(np.float32)\n",
        "        ys = ys.astype(np.int)\n",
        "        self.x_data = xs\n",
        "        self.y_data = ys\n",
        "        self.transform = transform #menyamakan variabel\n",
        "\n",
        "    def __len__(self): #metode yang mendefinisikan objek\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx): #indeks akses rentang nilai\n",
        "        x = Image.fromarray(self.x_data[idx].reshape(28, 28))\n",
        "        y = torch.tensor(np.array(self.y_data[idx]))\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        x = transforms.ToTensor()(np.array(x)/255)\n",
        "        return x, y #akhir fungsi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ru9L6-NzdkoA"
      },
      "outputs": [],
      "source": [
        "#membuat kelas model M3, untuk pilihan logdir pada saat train data\n",
        "class ModelM3(nn.Module):\n",
        "    def __init__(self): #inisialisasi fungsi\n",
        "        super(ModelM3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
        "        self.conv2_bn = nn.BatchNorm2d(48)\n",
        "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
        "        self.conv3_bn = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
        "        self.conv4_bn = nn.BatchNorm2d(80)\n",
        "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
        "        self.conv5_bn = nn.BatchNorm2d(96)\n",
        "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
        "        self.conv6_bn = nn.BatchNorm2d(112)\n",
        "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
        "        self.conv7_bn = nn.BatchNorm2d(128)\n",
        "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
        "        self.conv8_bn = nn.BatchNorm2d(144)\n",
        "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
        "        self.conv9_bn = nn.BatchNorm2d(160)\n",
        "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
        "        self.conv10_bn = nn.BatchNorm2d(176)\n",
        "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "\n",
        "    def get_logits(self, x): #mendapatlan log\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
        "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
        "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
        "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
        "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
        "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits # akhir fungsi\n",
        "\n",
        "    def forward(self, x): # mendapatkan outpun neural net\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dH1_RLrudz_3"
      },
      "outputs": [],
      "source": [
        "#membuat kelas model M5, untuk pilihan logdir pada saat train data\n",
        "class ModelM5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, bias=False)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False)\n",
        "        self.conv2_bn = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 96, 5, bias=False)\n",
        "        self.conv3_bn = nn.BatchNorm2d(96)\n",
        "        self.conv4 = nn.Conv2d(96, 128, 5, bias=False)\n",
        "        self.conv4_bn = nn.BatchNorm2d(128)\n",
        "        self.conv5 = nn.Conv2d(128, 160, 5, bias=False)\n",
        "        self.conv5_bn = nn.BatchNorm2d(160)\n",
        "        self.fc1 = nn.Linear(10240, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "        \n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        flat5 = torch.flatten(conv5.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat5))\n",
        "        return logits\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YiOFvl1Ed-OX"
      },
      "outputs": [],
      "source": [
        "#membuat kelas model M7, untuk pilihan logdir pada saat train data\n",
        "\n",
        "class ModelM7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM7, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 48, 7, bias=False)    # output becomes 22x22\n",
        "        self.conv1_bn = nn.BatchNorm2d(48)\n",
        "        self.conv2 = nn.Conv2d(48, 96, 7, bias=False)   # output becomes 16x16\n",
        "        self.conv2_bn = nn.BatchNorm2d(96)\n",
        "        self.conv3 = nn.Conv2d(96, 144, 7, bias=False)  # output becomes 10x10\n",
        "        self.conv3_bn = nn.BatchNorm2d(144)\n",
        "        self.conv4 = nn.Conv2d(144, 192, 7, bias=False) # output becomes 4x4\n",
        "        self.conv4_bn = nn.BatchNorm2d(192)\n",
        "        self.fc1 = nn.Linear(3072, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        flat1 = torch.flatten(conv4.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENDWGtI3F7nI",
        "outputId": "9b809ed8-d05f-400f-9491-b115e2dd24d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeds: 0\n",
            "Epoch: 6\n",
            "Trials: 4\n",
            "Kernel size: 7\n",
            "GPU: 0\n",
            "Logdir: modelM7\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 22, 22]           2,352\n",
            "       BatchNorm2d-2           [-1, 48, 22, 22]              96\n",
            "            Conv2d-3           [-1, 96, 16, 16]         225,792\n",
            "       BatchNorm2d-4           [-1, 96, 16, 16]             192\n",
            "            Conv2d-5          [-1, 144, 10, 10]         677,376\n",
            "       BatchNorm2d-6          [-1, 144, 10, 10]             288\n",
            "            Conv2d-7            [-1, 192, 4, 4]       1,354,752\n",
            "       BatchNorm2d-8            [-1, 192, 4, 4]             384\n",
            "            Linear-9                   [-1, 10]          30,720\n",
            "      BatchNorm1d-10                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 2,291,972\n",
            "Trainable params: 2,291,972\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.00\n",
            "Params size (MB): 8.74\n",
            "Estimated Total Size (MB): 9.74\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.610564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:992: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.594838\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.520621\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.323656\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.372170\n",
            "Best accuracy! correct images:  9903\n",
            "\n",
            "Test set: Average loss: 0.1359, Accuracy: 9903/10000 (99.03%) (best: 99.03%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.249459\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.193397\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.254284\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.220086\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.199676\n",
            "Best accuracy! correct images:  9924\n",
            "\n",
            "Test set: Average loss: 0.0841, Accuracy: 9924/10000 (99.24%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.138465\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.145364\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.161372\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.103480\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.251227\n",
            "\n",
            "Test set: Average loss: 0.0937, Accuracy: 9891/10000 (98.91%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.126431\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.091278\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.082434\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.122418\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.065585\n",
            "\n",
            "Test set: Average loss: 0.0678, Accuracy: 9915/10000 (99.15%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.126727\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.081948\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.135144\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.058394\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.050773\n",
            "\n",
            "Test set: Average loss: 0.1007, Accuracy: 9793/10000 (97.93%) (best: 99.24%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.142345\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.064264\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.110791\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.097010\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.044497\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0365, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 22, 22]           2,352\n",
            "       BatchNorm2d-2           [-1, 48, 22, 22]              96\n",
            "            Conv2d-3           [-1, 96, 16, 16]         225,792\n",
            "       BatchNorm2d-4           [-1, 96, 16, 16]             192\n",
            "            Conv2d-5          [-1, 144, 10, 10]         677,376\n",
            "       BatchNorm2d-6          [-1, 144, 10, 10]             288\n",
            "            Conv2d-7            [-1, 192, 4, 4]       1,354,752\n",
            "       BatchNorm2d-8            [-1, 192, 4, 4]             384\n",
            "            Linear-9                   [-1, 10]          30,720\n",
            "      BatchNorm1d-10                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 2,291,972\n",
            "Trainable params: 2,291,972\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.00\n",
            "Params size (MB): 8.74\n",
            "Estimated Total Size (MB): 9.74\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.617885\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.656328\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.484747\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.381328\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.311076\n",
            "Best accuracy! correct images:  9865\n",
            "\n",
            "Test set: Average loss: 0.1509, Accuracy: 9865/10000 (98.65%) (best: 98.65%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.259677\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.301852\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.187758\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.169565\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.140341\n",
            "\n",
            "Test set: Average loss: 0.1497, Accuracy: 9821/10000 (98.21%) (best: 98.65%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.154436\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.174457\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.175291\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.094184\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.167183\n",
            "\n",
            "Test set: Average loss: 0.0994, Accuracy: 9862/10000 (98.62%) (best: 98.65%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.173188\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.087816\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.088724\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.158758\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.157706\n",
            "Best accuracy! correct images:  9922\n",
            "\n",
            "Test set: Average loss: 0.0553, Accuracy: 9922/10000 (99.22%) (best: 99.22%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.105037\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.100009\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.071320\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.069616\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.044019\n",
            "\n",
            "Test set: Average loss: 0.0892, Accuracy: 9864/10000 (98.64%) (best: 99.22%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.090660\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.101790\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.092972\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.039176\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.081719\n",
            "\n",
            "Test set: Average loss: 0.0444, Accuracy: 9912/10000 (99.12%) (best: 99.22%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 22, 22]           2,352\n",
            "       BatchNorm2d-2           [-1, 48, 22, 22]              96\n",
            "            Conv2d-3           [-1, 96, 16, 16]         225,792\n",
            "       BatchNorm2d-4           [-1, 96, 16, 16]             192\n",
            "            Conv2d-5          [-1, 144, 10, 10]         677,376\n",
            "       BatchNorm2d-6          [-1, 144, 10, 10]             288\n",
            "            Conv2d-7            [-1, 192, 4, 4]       1,354,752\n",
            "       BatchNorm2d-8            [-1, 192, 4, 4]             384\n",
            "            Linear-9                   [-1, 10]          30,720\n",
            "      BatchNorm1d-10                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 2,291,972\n",
            "Trainable params: 2,291,972\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.00\n",
            "Params size (MB): 8.74\n",
            "Estimated Total Size (MB): 9.74\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.710074\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.646231\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.429995\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.405056\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.350317\n",
            "Best accuracy! correct images:  9843\n",
            "\n",
            "Test set: Average loss: 0.1794, Accuracy: 9843/10000 (98.43%) (best: 98.43%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.333373\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.307067\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.212345\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.294513\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.150769\n",
            "Best accuracy! correct images:  9904\n",
            "\n",
            "Test set: Average loss: 0.1114, Accuracy: 9904/10000 (99.04%) (best: 99.04%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.212611\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.123997\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.146065\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.126953\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.106251\n",
            "Best accuracy! correct images:  9920\n",
            "\n",
            "Test set: Average loss: 0.0689, Accuracy: 9920/10000 (99.20%) (best: 99.20%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.101709\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.134629\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.093308\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.140967\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.081278\n",
            "Best accuracy! correct images:  9929\n",
            "\n",
            "Test set: Average loss: 0.0558, Accuracy: 9929/10000 (99.29%) (best: 99.29%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.056713\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.059001\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.106956\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.116320\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.052091\n",
            "\n",
            "Test set: Average loss: 0.0526, Accuracy: 9921/10000 (99.21%) (best: 99.29%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.160164\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.080887\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.066416\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.093850\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.103892\n",
            "\n",
            "Test set: Average loss: 0.0470, Accuracy: 9917/10000 (99.17%) (best: 99.29%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 22, 22]           2,352\n",
            "       BatchNorm2d-2           [-1, 48, 22, 22]              96\n",
            "            Conv2d-3           [-1, 96, 16, 16]         225,792\n",
            "       BatchNorm2d-4           [-1, 96, 16, 16]             192\n",
            "            Conv2d-5          [-1, 144, 10, 10]         677,376\n",
            "       BatchNorm2d-6          [-1, 144, 10, 10]             288\n",
            "            Conv2d-7            [-1, 192, 4, 4]       1,354,752\n",
            "       BatchNorm2d-8            [-1, 192, 4, 4]             384\n",
            "            Linear-9                   [-1, 10]          30,720\n",
            "      BatchNorm1d-10                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 2,291,972\n",
            "Trainable params: 2,291,972\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.00\n",
            "Params size (MB): 8.74\n",
            "Estimated Total Size (MB): 9.74\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.720558\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.684372\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.532986\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.366190\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.374117\n",
            "Best accuracy! correct images:  9846\n",
            "\n",
            "Test set: Average loss: 0.1572, Accuracy: 9846/10000 (98.46%) (best: 98.46%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.290665\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.229559\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.186227\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.236315\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.210658\n",
            "Best accuracy! correct images:  9905\n",
            "\n",
            "Test set: Average loss: 0.0833, Accuracy: 9905/10000 (99.05%) (best: 99.05%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.229073\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.170357\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.226132\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.121536\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.113283\n",
            "\n",
            "Test set: Average loss: 0.0724, Accuracy: 9905/10000 (99.05%) (best: 99.05%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.113894\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.131200\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.054642\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.122432\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.142656\n",
            "\n",
            "Test set: Average loss: 0.0800, Accuracy: 9890/10000 (98.90%) (best: 99.05%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.081077\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.092095\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.205987\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.116106\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.094100\n",
            "\n",
            "Test set: Average loss: 0.0891, Accuracy: 9825/10000 (98.25%) (best: 99.05%)\n",
            "\n",
            "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.078078\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.103517\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.056467\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.036543\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.083251\n",
            "\n",
            "Test set: Average loss: 0.0782, Accuracy: 9885/10000 (98.85%) (best: 99.05%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#menjalankan percobaan (train)\n",
        "\n",
        "def run(p_seed=0, p_epochs=150, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "    # nomor acak pada generator seed\n",
        "    SEED = p_seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # kernel size model\n",
        "    KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "    # nomor epochs\n",
        "    NUM_EPOCHS = p_epochs\n",
        "\n",
        "    # mengambil alamat nama file log pada drive\n",
        "    if not os.path.exists(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/%s\"%p_logdir):\n",
        "        os.makedirs(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/%s\"%p_logdir)\n",
        "    OUTPUT_FILE = str(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/%s/log%03d.out\"%(p_logdir,SEED))\n",
        "    MODEL_FILE = str(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,SEED))\n",
        "\n",
        "    # mengaktifkan GPU\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # metode augmentasi data\n",
        "    transform = transforms.Compose([\n",
        "        RandomRotation(20, seed=SEED),\n",
        "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "        ])\n",
        "\n",
        "    # memuat data \n",
        "    train_dataset = MnistDataset(training=True, transform=transform)\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=120, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # seleksi model\n",
        "    if(KERNEL_SIZE == 3):\n",
        "        model = ModelM3().to(device)\n",
        "    elif(KERNEL_SIZE == 5):\n",
        "        model = ModelM5().to(device)\n",
        "    elif(KERNEL_SIZE == 7):\n",
        "        model = ModelM7().to(device)\n",
        "\n",
        "    summary(model, (1, 28, 28))\n",
        "\n",
        "    # memilih hyperparameter\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    # menghapus file hasil\n",
        "    f = open(OUTPUT_FILE, 'w')\n",
        "    f.close()\n",
        "\n",
        "    # variabel global\n",
        "    g_step = 0\n",
        "    max_correct = 0\n",
        "\n",
        "    # pengulangan percobaan (training) dan evaluasi\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # proses training                                                         \n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_corr = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            train_pred = output.argmax(dim=1, keepdim=True)\n",
        "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
        "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            g_step += 1\n",
        "            ema(model, g_step)\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = 100 * train_corr / len(train_loader.dataset)\n",
        "\n",
        "        # proses test                                                            \n",
        "        model.eval()\n",
        "        ema.assign(model)\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_pred = np.zeros(0)\n",
        "        total_target = np.zeros(0)\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                total_pred = np.append(total_pred, pred.cpu().numpy())\n",
        "                total_target = np.append(total_target, target.cpu().numpy())\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            if(max_correct < correct):\n",
        "                torch.save(model.state_dict(), MODEL_FILE)\n",
        "                max_correct = correct\n",
        "                print(\"Best accuracy! correct images: %5d\"%correct)\n",
        "        ema.resume(model)\n",
        "\n",
        "        # output                                                                   \n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "        best_test_accuracy = 100 * max_correct / len(test_loader.dataset)\n",
        "\n",
        "        #menampilkan hasil akurasi tes\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) (best: {:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), test_accuracy, best_test_accuracy))\n",
        "\n",
        "        f = open(OUTPUT_FILE, 'a')\n",
        "        f.write(\" %3d %12.6f %9.3f %12.6f %9.3f %9.3f\\n\"%(epoch, train_loss, train_accuracy, test_loss, test_accuracy, best_test_accuracy))\n",
        "        f.close()\n",
        "\n",
        "        # update penjadwal tingkat pembelajaran                                           \n",
        "        lr_scheduler.step()\n",
        "\n",
        "#seed untuk menentukan nilai awal\n",
        "p_seed = int(input (\"Seeds: \")) # memasukkan angka sebagai input seed\n",
        "\n",
        "#epoch digunakan untuk melakukan pengulangan (sesuai input) terhadap trial yang dijalankan\n",
        "p_epoch = int(input (\"Epoch: \")) # memasukkan angka sebagai input epoch\n",
        "\n",
        "#trial digunakan untuk pengulangan percobaan\n",
        "p_trials = int(input (\"Trials: \")) # memasukkan angka sebagai input epoch\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #memasukkan angka sebagai input epoch (disesuaikan dengan angka pada model)\n",
        "\n",
        "#gpu untuk menjalankan program pada grafik card\n",
        "p_gpu = int(input (\"GPU: \")) #masukkan angka sebagai input GPU\n",
        "\n",
        "p_logdir = input (\"Logdir: \") #masukkan input model yang akan digunakan\n",
        "\n",
        "#menjalankan GPU\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(p_gpu)\n",
        "\n",
        "for x in range (p_trials): #pengulangan percobaan (trial)\n",
        "  run(p_seed + x, p_epoch, p_kernel_size, p_logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "keF49DHxChUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2edc51f9-5a96-4481-e5a4-c63be1ae8499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logdir: modelM7\n",
            "Seeds: 0\n",
            "Trials: 4\n",
            "Kernel size: 7\n",
            "64 [359, 445, 582, 625, 674, 716, 882, 1226, 1232, 1364, 1393, 1737, 1868, 1878, 1901, 2035, 2040, 2130, 2293, 2406, 2414, 2462, 2597, 2654, 2760, 2939, 3060, 3073, 3225, 3422, 3534, 3558, 3762, 3808, 3821, 3869, 3985, 4201, 4284, 4369, 4497, 4547, 4761, 4823, 5654, 5937, 6558, 6571, 6576, 6625, 8275, 8279, 8316, 8325, 8326, 8408, 9009, 9015, 9019, 9024, 9679, 9729, 9749, 9754]\n",
            "78 [18, 359, 447, 449, 582, 619, 659, 674, 696, 716, 938, 1014, 1112, 1226, 1232, 1459, 1621, 1681, 1709, 1737, 1868, 1901, 2018, 2035, 2040, 2130, 2148, 2182, 2280, 2293, 2343, 2462, 2488, 2582, 2597, 2939, 3073, 3225, 3266, 3422, 3534, 3558, 3601, 3762, 3859, 4163, 4176, 4201, 4369, 4443, 4497, 4507, 4740, 4759, 4761, 4860, 5457, 5654, 5937, 5955, 6571, 6572, 6597, 6883, 7216, 8094, 8275, 8316, 8325, 8408, 8527, 9530, 9540, 9595, 9664, 9679, 9729, 9754]\n",
            "71 [447, 582, 625, 674, 726, 846, 947, 1112, 1156, 1226, 1299, 1328, 1393, 1522, 1621, 1737, 1754, 1868, 1901, 2035, 2040, 2118, 2130, 2148, 2293, 2447, 2462, 2488, 2597, 3073, 3225, 3422, 3534, 3558, 3762, 3767, 3808, 4053, 4199, 4201, 4248, 4443, 4860, 5457, 5654, 5888, 5937, 5955, 5997, 6558, 6561, 6576, 6755, 6783, 6883, 7216, 8059, 8275, 8279, 8316, 8408, 8527, 9009, 9015, 9019, 9024, 9700, 9729, 9749, 9754, 9792]\n",
            "95 [92, 104, 445, 449, 582, 625, 646, 659, 716, 726, 882, 938, 947, 1039, 1068, 1226, 1232, 1290, 1299, 1393, 1508, 1621, 1681, 1737, 1754, 1790, 1868, 1901, 2035, 2040, 2052, 2135, 2182, 2293, 2422, 2433, 2462, 2488, 2597, 2654, 2823, 2927, 2939, 2945, 3005, 3073, 3132, 3225, 3316, 3422, 3475, 3558, 3762, 3821, 3850, 3859, 3869, 3906, 3985, 4053, 4176, 4201, 4369, 4443, 4497, 4547, 4551, 4740, 4761, 4823, 4990, 5086, 5165, 5457, 5955, 6576, 6625, 6651, 6755, 6783, 8094, 8279, 8316, 8322, 8382, 8408, 9009, 9015, 9664, 9679, 9700, 9729, 9749, 9754, 9850]\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "#fungsi untuk run test data\n",
        "def run(p_seed=0, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "\n",
        "    # mengaktifkan GPU\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # menjalankan data\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # seleksi model yang digunakan\n",
        "    if(p_kernel_size == 3):\n",
        "        model1 = ModelM3().to(device)\n",
        "    elif(p_kernel_size == 5):\n",
        "        model1 = ModelM5().to(device)\n",
        "    elif(p_kernel_size == 7):\n",
        "        model1 = ModelM7().to(device)\n",
        "\n",
        "    #mengambil data pada drive\n",
        "    model1.load_state_dict(torch.load(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/%s/model%03d.pth\"%(p_logdir,p_seed)))\n",
        "\n",
        "    model1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    wrong_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model1(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            wrong_images.extend(np.nonzero(~pred.eq(target.view_as(pred)).cpu().numpy())[0]+(100*batch_idx))\n",
        "\n",
        "    # menyimpan data pada drive\n",
        "    np.savetxt(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/%s/wrong%03d.txt\"%(p_logdir,p_seed), wrong_images, fmt=\"%d\")\n",
        "    # menampilkan gambar yang salah penebakan\n",
        "    print(len(wrong_images), wrong_images)\n",
        "\n",
        "p_logdir = input (\"Logdir: \") #masukkan input model yang akan digunakan\n",
        "p_seed = int(input (\"Seeds: \")) # input angka untuk seed\n",
        "p_trials = int(input (\"Trials: \")) # masukkan angka sebagi input berapa kali percobaan\n",
        "p_kernel_size = int (input (\"Kernel size: \")) # masukkan angka sebagai input ukuran kernel (menyesuaikan angka pada model)\n",
        "\n",
        "for y in range (p_trials): #perulangan percobaan (trial)\n",
        "  run(p_seed + y, p_kernel_size, p_logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YsLIRZSmCyeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9189b608-693f-4186-eaf7-d5ee0b4aa3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel size: 7\n",
            "   1   64   78   71   59   59\n",
            "   2   64   78   95   67   59\n",
            "   3   64   71   95   66   59\n",
            "   4   78   71   95   70   59\n"
          ]
        }
      ],
      "source": [
        "#inisialisai nilai variabel\n",
        "cnt = 1\n",
        "best = 10000\n",
        "curr = 10000\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) #input ukuran kernel \n",
        "\n",
        "KERNEL_SIZE = p_kernel_size #menyamakan variabel\n",
        "\n",
        "for i in range(4): #perulangan train (mengikuti jumlah trial yang digunakan)\n",
        "    for j in range(i+1,4):\n",
        "        for k in range(j+1,4):\n",
        "          #mengambil data dari drive\n",
        "            w1 = np.loadtxt(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, i)).astype(np.int)\n",
        "            w2 = np.loadtxt(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, j)).astype(np.int)\n",
        "            w3 = np.loadtxt(\"/content/drive/MyDrive/MnistSimpleCNN-master/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, k)).astype(np.int)\n",
        "\n",
        "            board = np.zeros((10000))\n",
        "            board[w1] += 1\n",
        "            board[w2] += 1\n",
        "            board[w3] += 1\n",
        "            board = board // 2\n",
        "            curr = np.sum(board)\n",
        "            if curr < best:\n",
        "                best = curr\n",
        "            print(\"%4d %4d %4d %4d %4d %4d\"%(cnt, len(w1), len(w2), len(w3), curr, best))\n",
        "            cnt += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "paper1-UAS ML.ipynb",
      "provenance": [],
      "mount_file_id": "1nbnp5UQkKz7wWPzFdQXeyiVddyQwNa8-",
      "authorship_tag": "ABX9TyPSFSrdcX5hL7SxerjZvJNA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}